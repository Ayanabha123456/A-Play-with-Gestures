{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c9778ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e5580",
   "metadata": {},
   "source": [
    "### train(), test() - uses data provided to class during initialization\n",
    "### train_seperate(), test_seperate() - uses data directly provided to these functions during call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea129c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest:\n",
    "    def __init__(self,data,test_size):\n",
    "        self.ts=test_size\n",
    "        self.df=data\n",
    "    \n",
    "    def train(self):\n",
    "        #train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.df.iloc[:,1:-1], self.df.iloc[:,-1], test_size=self.ts, random_state=42)\n",
    "        \n",
    "        self.test_X = X_test\n",
    "        self.test_y = y_test\n",
    "        #model-training\n",
    "        clf = RandomForestClassifier(n_estimators = 100,random_state=5)\n",
    "        clf.fit(X_train,y_train)\n",
    "        self.model = clf\n",
    "        \n",
    "    def test(self):\n",
    "        y_pred = self.model.predict(self.test_X)\n",
    "        print(accuracy_score(y_pred,self.test_y))\n",
    "    \n",
    "    def train_seperate(self,X_train,y_train):\n",
    "        clf = RandomForestClassifier(n_estimators = 100,random_state=5)\n",
    "        clf.fit(X_train,y_train)\n",
    "        self.model = clf\n",
    "    \n",
    "    def test_seperate(self,X_test,y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(accuracy_score(y_pred,y_test))\n",
    "        \n",
    "class XGBoost:\n",
    "    def __init__(self,data,test_size):\n",
    "        self.ts=test_size\n",
    "        self.df=data\n",
    "        \n",
    "    def train(self):\n",
    "        #train-test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.df.iloc[:,1:-1], self.df.iloc[:,-1], test_size=self.ts, random_state=42)\n",
    "\n",
    "        self.test_X = X_test\n",
    "        self.test_y = y_test\n",
    "        #model-training\n",
    "        clf = xgb.XGBClassifier(random_state=5)\n",
    "        clf.fit(X_train,y_train)\n",
    "        self.model = clf\n",
    "        \n",
    "    def test(self):\n",
    "        y_pred = self.model.predict(self.test_X)\n",
    "        print(accuracy_score(y_pred,self.test_y))\n",
    "    \n",
    "    def train_seperate(self,X_train,y_train):\n",
    "        clf = xgb.XGBClassifier(random_state=5)\n",
    "        clf.fit(X_train,y_train)\n",
    "        self.model = clf\n",
    "    \n",
    "    def test_seperate(self,X_test,y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718fa57",
   "metadata": {},
   "source": [
    "# ASL fingerspell "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a56bdf9",
   "metadata": {},
   "source": [
    "#### Hand Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62416995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User A\n",
    "df=pd.read_csv('Datasets\\\\imageData_ASL_fingerspell.csv')\n",
    "test_indices=[i for i in range(0,12397)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "808914a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a10b20d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8547229168347181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8791643139469226\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "336e4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User B\n",
    "test_indices=[i for i in range(12397,26238)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f6b0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "758aac64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856946752402283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:16:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8877971244852251\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7791b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User C\n",
    "test_indices=[i for i in range(26238,39614)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c0e8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f33e42ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93436004784689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:25:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9478917464114832\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b8663d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User D\n",
    "test_indices=[i for i in range(39614,52055)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dec30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "610efa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8558797524314765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8727594244835624\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74959fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User E\n",
    "test_indices=[i for i in range(52055,df.shape[0])]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1189977",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bb95366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9222222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:37:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9238654147104851\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a1677",
   "metadata": {},
   "source": [
    "#### Convolutional features + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0cc2786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User A\n",
    "df=pd.read_csv('imageData2_ASL_fingerspell.csv')\n",
    "test_indices=[i for i in range(0,12547)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0c6fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e6da1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34430541165218775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:03:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.35928907308519964\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fd7e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User B\n",
    "test_indices=[i for i in range(12547,26445)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8949133",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0991d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4009209958267377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:14:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.4269679090516621\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eb9c0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User C\n",
    "test_indices=[i for i in range(26445,39838)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c2b2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06731fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38968117673411484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:26:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.42036884939893976\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "685aff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User D\n",
    "test_indices=[i for i in range(39838,52992)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84aefefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea97e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2564999239774973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:37:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.2824996198874867\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "139aab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User E\n",
    "test_indices=[i for i in range(52992,df.shape[0])]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9410dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c42335bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4397590361445783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.4861524018150524\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f5844",
   "metadata": {},
   "source": [
    "#### Convolutional features + finger angles + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1446b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User A\n",
    "df=pd.read_csv('imageData3_ASL_fingerspell.csv')\n",
    "test_indices=[i for i in range(0,12397)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ab45a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f98ba64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3507300153262886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:13:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.3846898443171735\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac976ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User B\n",
    "test_indices=[i for i in range(12397,26238)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9e3f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d1372367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3908677118705296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:26:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.4348674228740698\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1ab0f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User C\n",
    "test_indices=[i for i in range(26238,39614)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d44f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ade4af80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3688696172248804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.41245514354066987\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f3b15223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User D\n",
    "test_indices=[i for i in range(39614,52055)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "098afad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b5dc84e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2572140503174986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:48:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.2572944297082228\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b567161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User E\n",
    "test_indices=[i for i in range(52055,df.shape[0])]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1cd9dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a75b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4057120500782473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.45704225352112676\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04432f",
   "metadata": {},
   "source": [
    "#### CNN features on hand edges + PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c477f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User A\n",
    "df=pd.read_csv('imageData4_ASL_fingerspell.csv')\n",
    "test_indices=[i for i in range(0,12547)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "986efe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1461cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3070056587232008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:10:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.30692595839642944\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b37f8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User B\n",
    "test_indices=[i for i in range(12547,26445)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c479df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee0e2c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23082457907612605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.2318319182616204\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6318aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User C\n",
    "test_indices=[i for i in range(26445,39838)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8422b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8a5a929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27447173896811766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:34:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.2752930635406556\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fec2bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User D\n",
    "test_indices=[i for i in range(39838,52992)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "02e9a3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b07438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26805534438193707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.25771628402006996\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d1ae1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User E\n",
    "test_indices=[i for i in range(52992,df.shape[0])]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54720ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ab439a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3942262556720388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:58:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.4225473321858864\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d4088",
   "metadata": {},
   "source": [
    "#### L.C. of BRISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abe9c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User A\n",
    "df=pd.read_csv('Datasets\\\\imageData5_ASL_fingerspell.csv')\n",
    "test_indices=[i for i in range(0,12547)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eba3f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41de9543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1291145293695704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.13756276400733242\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e35e50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User B\n",
    "test_indices=[i for i in range(12547,26445)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e7ad6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b8c4312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1573607713340049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.15347532018995538\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e9405fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User C\n",
    "test_indices=[i for i in range(26445,39838)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61601af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7f9a8714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13477189576644516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:36:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.1418651534383633\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fae773f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User D\n",
    "test_indices=[i for i in range(39838,52992)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "78870321",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dda54123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098069028432416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:50:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.09784096092443363\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd963ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User E\n",
    "test_indices=[i for i in range(52992,df.shape[0])]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3e4b64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "35a3c175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1588170865279299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:01:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.15443592552026286\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81465a",
   "metadata": {},
   "source": [
    "#### CNN features on BRISK image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "97ba18cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User A\n",
    "df=pd.read_csv('imageData6_ASL_fingerspell.csv')\n",
    "test_indices=[i for i in range(0,12547)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6134b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "586c81f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34143619988841956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.3710050211205866\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "20769b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User B\n",
    "test_indices=[i for i in range(12547,26445)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "16d0353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "21ad1067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36350554036552024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.37343502662253564\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b0db25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User C\n",
    "test_indices=[i for i in range(26445,39838)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce0f0c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7a129520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.350257597252296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:42:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.3682520719778989\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ed1a57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User D\n",
    "test_indices=[i for i in range(39838,52992)]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a67d1c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de15cfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24129542344533983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:55:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.23787441082560437\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d8a66196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User E\n",
    "test_indices=[i for i in range(52992,df.shape[0])]\n",
    "ind=df.index.isin(test_indices)\n",
    "df1=df[~ind]\n",
    "df2=df[ind]\n",
    "df1=df1.iloc[:,1:]\n",
    "df2=df2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "92de63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df1.iloc[:,:-1]\n",
    "y_train=df1.iloc[:,-1]\n",
    "X_test=df2.iloc[:,:-1]\n",
    "y_test=df2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c2ca0d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35847285244875604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:07:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.39156626506024095\n"
     ]
    }
   ],
   "source": [
    "x=Random_Forest(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)      \n",
    "\n",
    "\n",
    "x=XGBoost(df,0.2)\n",
    "x.train_seperate(X_train,y_train)\n",
    "x.test_seperate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed4d6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
